#!/usr/bin/env python
import os
import sys
from os.path import isfile, join, dirname, abspath
import click
import subprocess
from ngs_utils.file_utils import verify_file, safe_mkdir, verify_dir
from ngs_utils import logger
from umccrise import package_path
from ngs_utils.utils import set_locale; set_locale()


@click.command()
@click.argument('bcbio_project', type=click.Path(exists=True))
@click.argument('target_rule', nargs=-1)
@click.option('-o', 'output_dir', type=click.Path(), help='Output directory (default is "umccrise")')
@click.option('-j', '--jobs', 'jobs', default=1, help='Maximum number of cores to use at single time (works both for local '
              'and cluster runs)')
@click.option('-s', '--sample', 'sample', help='Comma-separated list of samples or batches to process')
@click.option('-b', '--batch', 'batch', help='Comma-separated list of samples or batches to process')
@click.option('-e', '--exclude', 'exclude', help='Comma-separated list of samples or batches to ignore')
@click.option('-c', '--cluster-auto', 'cluster', is_flag=True, help='Submit jobs to cluster')
@click.option('--cluster', '--cluster-cmd', 'cluster_cmd', help='Deprecated. Use --cluster-auto instead')
@click.option('--unlock', is_flag=True, help='Propagaded to snakemake')
@click.option('--rerun-incomplete', is_flag=True, help='Propagaded to snakemake')

@click.option('--docker', '--dockerized', is_flag=True, help='Pull umccr/umccrise docker image and use it instead')
@click.option('--pon', '--panel-of-normals', help='Path to panel of normals folder '
              '(see https://github.com/umccr/vcf_stuff#building-the-panel on how to prepare it)')
@click.option('--bcbio-genomes', help='Path to bcbio-nextgen reference data '
              '(seq/{genome}.fa and validation/giab-NA12878/truth_regions.bed are used)')

def main(bcbio_project, target_rule=list(), output_dir=None, jobs=None, sample=None, batch=None, exclude=None,
         cluster=False, cluster_cmd=None, unlock=False, rerun_incomplete=False, dockerized=False,
         panel_of_normals=None, bcbio_genomes=None):
    """
Umccrise (post-process) a bcbio project.\n
BCBIO_PROJECT: path to a bcbio run (final or "datestamp" directory)\n
TARGET_RULE: optional list of rules, e.g.: pcgr coverage structural small_variants rmd igv
"""

    output_dir = output_dir or 'umccrised'
    output_dir = abspath(output_dir)
    safe_mkdir(output_dir)
    logger.init(log_fpath_=join(output_dir, 'umccrise.log'), save_previous=True)

    bcbio_project = verify_dir(bcbio_project)

    conf = f'run_dir={bcbio_project if not dockerized else "/bcbio_project"}'
    if sample:
        conf += f' sample={sample}'
    if batch:
        conf += f' batch={batch}'
    if exclude:
        conf += f' exclude={exclude}'
    target_rule = list(target_rule)
    if 'pcgr_download' in target_rule:
        conf += f' pcgr_download=yes'
    if bcbio_genomes:
        bcbio_genomes = verify_dir(bcbio_genomes)
        conf += f' bcbio_genomes={bcbio_genomes if not dockerized else "/bcbio_genomes"}'
    if panel_of_normals:
        panel_of_normals = verify_dir(panel_of_normals)
        conf += f' pon={panel_of_normals if not dockerized else "/panel_of_normals"}'

    cluster_param = ''
    if not dockerized and (cluster or cluster_cmd):
        if not cluster_cmd:
            from python_utils.hpc import get_loc
            loc = get_loc()
            if not loc.submit_job_cmd:
                logger.critical(f'Automatic cluster submission is not supported for the machine "{loc.name}"')
            cluster_wrapper = join(package_path(), 'submit.py')
            cluster_cmd = f'python {cluster_wrapper}'
        cluster_param = f' --cluster "{cluster_cmd}"'

    cmd = ''
    if dockerized:
        cpus_avail = int(subprocess.check_output('docker system info | grep CPUs', shell=True).decode().split(': ')[1])
        if jobs > cpus_avail:
            click.echo(click.style(
                f'Warning: the number of jobs requested {jobs} is higher than then number of available CPUs '
                f'for the docker machine {cpus_avail}. Downgrading requested jobs to {cpus_avail}.', fg='red'))
            jobs = cpus_avail

        cmd = (
            f'docker run -t '
            f'--cpus {jobs} '
            f'-v={bcbio_project}:/bcbio_project '
            f'-v={output_dir}:/output_dir ')
        if panel_of_normals:
            cmd += f'-v={panel_of_normals}:/panel_of_normals '
        if bcbio_genomes:
            cmd += f'-v={bcbio_genomes}:/bcbio_genomes '

        cmd += f'umccr/umccrise:latest '

    snakefile = join(package_path(), "Snakefile") if not dockerized else "/umccrise/umccrise/Snakefile"
    output_dir = output_dir if not dockerized else "/output_dir"
    cmd += (
        f'snakemake '
        f'{" ".join(target_rule)} '
        f'--snakefile {snakefile} '
        f'--printshellcmds '
        f'--report {output_dir}/log/snakemake_report.html '
        f'--directory {output_dir} '
        f'-j {jobs} '
        f'--rerun-incomplete ' 
        f'{cluster_param} '
        f'--config {conf} '
    )

    if unlock:
        print('* Unlocking previous run... *')
        print(cmd + ' --unlock')
        subprocess.call(cmd + ' --unlock', shell=True)
        print('* Now rerunning *')

    print(cmd)
    exit_code = subprocess.call(cmd, shell=True)
    if exit_code != 0:
        logger.error('--------')
        logger.error(f'Error running Umccrise: snakemake returned a non-zero status. Working directory: {output_dir}')
        sys.exit(exit_code)
    logger.info(f'Output directory: {output_dir}')

    # Cleanup
    # work_dir = join(output_dir, 'work')
    # if isdir(work_dir):
    #     shutils.rmtree(work_dir)


if __name__ == '__main__':
    main()
