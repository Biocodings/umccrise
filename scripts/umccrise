#!/usr/bin/env python
import os
import sys
from os.path import isfile, join, dirname, abspath
import click
import subprocess

from ngs_utils.call_process import run_simple
from ngs_utils.file_utils import verify_file, safe_mkdir, verify_dir
from ngs_utils import logger
from ngs_utils.logger import warn, info
from ngs_utils.utils import set_locale; set_locale()
from ngs_utils import snakemake_utils
from umccrise import package_path
from umccrise import _version as version


@click.command()
@click.version_option(version.__version__)
@click.argument('bcbio_project', type=click.Path(exists=True))
@click.argument('target_rule', nargs=-1)
@click.option('-o', 'output_dir', type=click.Path(), help='Output directory [def: umccrised]')

@click.option('-s', '--sample', 'sample', help='Comma-separated list of samples or batches to process')
@click.option('-b', '--batch', 'batch', help='Comma-separated list of samples or batches to process')
@click.option('-e', '--exclude', 'exclude', help='Comma-separated list of samples or batches to ignore')
@click.option('--genomes', '--genomes-dir', 'genomes_dir', help='Path to the reference data')

# Cluster:
@click.option('-j', '--jobs', 'jobs', default=1, help='Maximum number of cores to use at single time (works both for '
              'local and cluster runs)')
@click.option('-c', '--cluster-auto', 'cluster', is_flag=True, help='Submit jobs to cluster')
@click.option('--cluster', '--cluster-cmd', 'cluster_cmd', help='Deprecated. Use --cluster-auto instead')

# Snakemake:
@click.option('--forcerun', 'forcerun', help='Comma-separated rules that will be run even if the outputs exist. Propagated to snakemake, space-separated.')
@click.option('--unlock', is_flag=True, help='Use when you are rerunning after Ctrl+C. Propagated to snakemake.')
@click.option('--rerun-incomplete', is_flag=True, help='[Deprecated]. Propagated to snakemake. Set by default, ignored.')
@click.option('--restart-times', default=0, help='Propagated to snakemake. Default is 0.')
@click.option('-n', '--dryrun', 'dryrun', is_flag=True, help='Propagated to snakemake. Prints rules and commands '
                                                             'to be run without actually executing them.')
@click.option('--report', 'report', help='Propagated to snakemake. Create an HTML report with results and statistics. '
                                         'Needs to end in ".html".')
@click.option('--dag', 'dag', is_flag=True, help='Propagated to snakemake. Print the DAG of jobs in the dot language. '
                                                 'Usage: umccrise --dag > tmp.txt; cat <cleaned-tmp.txt> | dot -Tsvg > dag.svg')
# Other:
@click.option('--no-s3', is_flag=True, help='Do not attempt to upload results to s3')
@click.option('--no-igv', is_flag=True, help='Skip generating of minibams')

@click.option('--docker', '--docker-wrapper-mode', 'docker_wrapper_mode', is_flag=True,
              help='Pull umccr/umccrise docker image and use it instead of the main codebase')

def main(bcbio_project, target_rule=list(), output_dir=None, sample=None, batch=None, exclude=None, genomes_dir=None,
         jobs=None, cluster=False, cluster_cmd=None, forcerun=None,
         unlock=False, rerun_incomplete=False, restart_times=None, dryrun=False,
         no_s3=None, no_igv=False, docker_wrapper_mode=False, report=None, dag=False):
    """
Umccrise (post-process) a bcbio project.\n
BCBIO_PROJECT: path to a bcbio run (final or "datestamp" directory)\n
TARGET_RULE: optional list of rules, e.g.: pcgr coverage structural small_variants rmd igv
"""

    output_dir = output_dir or 'umccrised'
    output_dir = safe_mkdir(abspath(output_dir))
    log_dir = safe_mkdir(join(output_dir, 'log'))
    logger.init(log_fpath_=join(log_dir, 'command.txt'), save_previous=True)

    if isfile(join(output_dir, 'all.done')):
        run_simple('touch ' + join(output_dir, 'all.done'))

    conf = dict()
    docker_mounts = dict()

    #######################
    #### Setting paths ####
    #######################

    if docker_wrapper_mode:
        docker_mounts[output_dir] = '/output_dir'

    conf['bcbio_project'] = verify_dir(bcbio_project, is_critical=True)
    if docker_wrapper_mode:
        conf['bcbio_project'] = docker_mounts[bcbio_project] = '/bcbio_project'

    if genomes_dir:
        conf['genomes_dir'] = verify_dir(genomes_dir, is_critical=True)
        if docker_wrapper_mode:
            conf['genomes_dir'] = docker_mounts[genomes_dir] = '/genomes'

    #####################################
    #### Setting non-path parameters ####
    #####################################

    if sample or batch:
        conf['sample'] = sample or batch
    if exclude:
        conf['exclude'] = exclude
    target_rule = list(target_rule)
    if 'pcgr_download' in target_rule:
        conf['pcgr_download'] = 'yes'

    if not no_s3:
        if os.environ.get('AWS_PROFILE') != 'umccr':
            warn('To upload minibams to s3://umccr-igv, please set AWS_PROFILE=umccr')
            info()
            no_s3 = True
    conf['no_s3'] = 'yes' if no_s3 else 'no'
    conf['no_igv'] = 'yes' if no_igv else 'no'

    conf['total_cores'] = jobs

    if unlock:
        conf['unlock'] = 'yes'

    #########################
    #### Setting cluster ####
    #########################

    cluster_param = ''
    cluster_log_dir = ''
    if (cluster or cluster_cmd) and not docker_wrapper_mode:
        if cluster_cmd:
            cluster_param = f' --cluster "{cluster_cmd}"'
        else:
            cluster_log_dir = safe_mkdir(join(log_dir, 'cluster'))
            cluster_param = snakemake_utils.make_cluster_cmdl(cluster_log_dir, 'umccrise')

    ###############################
    #### Building command line ####
    ###############################

    cmd = ''
    if docker_wrapper_mode:
        cpus_avail = int(subprocess.check_output('docker system info | grep CPUs', shell=True).decode().split(': ')[1])
        if jobs > cpus_avail:
            click.echo(click.style(
                f'Warning: the number of jobs requested {jobs} is higher than the number of available CPUs '
                f'for the docker machine {cpus_avail}. Downgrading requested jobs to {cpus_avail}.', fg='red'))
            jobs = cpus_avail

        docker_tag = 'umccr/umccrise'
        # if pcgr_data:
        #     docker_tag = 'umccr/umccrise_with_pcgr'

        cmd = (
            f'docker run -t ' +
            f'--cpus {jobs} ' +
            ''.join(f'-v={k}:{v} ' for k, v in docker_mounts.items()) +
            f'{docker_tag} '
        )

    snakefile = join(package_path(), 'Snakefile') if not docker_wrapper_mode else '/umccrise/umccrise/Snakefile'
    cmd += (
        f'snakemake '
        f'{" ".join(target_rule)} '
        f'--snakefile {snakefile} '
        f'--printshellcmds '
        f'{"--dryrun " if dryrun else ""}'
        f'{"--dag " if dag else ""}'
        f'{f"--report {report} " if report else ""}'
        f'--directory {output_dir if not docker_wrapper_mode else "/output_dir"} '
        f'-j {jobs} '
        f'--rerun-incomplete '
        f'--restart-times {restart_times} '
        f'{cluster_param} '
        f'--config {" ".join(k + "=" + str(v) for k, v in conf.items())} '
    )

    #################
    #### Running ####
    #################

    if unlock:
        print('* Unlocking previous run... *')
        run_simple(cmd + ' --unlock')
        print('* Now rerunning *')

    try:
        run_simple(cmd)
    except subprocess.CalledProcessError:
        logger.error('--------')
        logger.error(f'Error running Umccrise: snakemake returned a non-zero status. Working directory: {output_dir}')
        if cluster_log_dir:
            run_simple(f'chmod -R a+r {cluster_log_dir}', silent=True)
            logger.error(f'Review cluster job logs in {cluster_log_dir}')
        sys.exit(1)
    except KeyboardInterrupt:
        logger.error('--------')
        logger.error(f'Interrupted Umccrise. Fixing logs permissions. Working directory: {output_dir}')
        if cluster_log_dir:
            run_simple(f'chmod -R a+r {cluster_log_dir}', silent=True)
            logger.error(f'Review cluster job logs in {cluster_log_dir}')
        sys.exit(1)
    else:
        logger.info('--------')
        if cluster_log_dir:
            run_simple(f'chmod -R a+r {cluster_log_dir}', silent=True)
        logger.info(f'Finished. Output directory: {output_dir}')


if __name__ == '__main__':
    main()
