#!/usr/bin/env python
import os
import sys
import traceback
from os.path import isfile, join, dirname, abspath, isdir
import click
import subprocess
from glob import glob
import tempfile

from ngs_utils.call_process import run_simple
from ngs_utils.file_utils import verify_file, safe_mkdir, verify_dir, splitext_plus
from ngs_utils import logger
from ngs_utils.logger import warn, info, critical
from ngs_utils.utils import set_locale; set_locale()
from ngs_utils import snakemake_utils
from umccrise import package_path
from umccrise import _version as version
from hpc_utils import hpc


@click.command()
@click.version_option(version.__version__)
@click.argument('input_project', type=click.Path(exists=True))
@click.argument('target_rule', nargs=-1)
@click.option('-o', 'output_dir', type=click.Path(), help='Output directory [def: umccrised]')

@click.option('-s', '--sample', 'sample', help='Comma-separated list of samples or batches to process')
@click.option('-b', '--batch', 'batch', help='Comma-separated list of samples or batches to process')
@click.option('-e', '--exclude', 'exclude', help='Comma-separated list of samples or batches to ignore')
@click.option('--genomes', '--genomes-dir', 'input_genomes_dir', help='Path to the reference data')

# Cluster:
@click.option('-j', '--jobs', 'jobs', default=1, help='Maximum number of cores to use at single time (works both for '
              'local and cluster runs)')
@click.option('-c', '--cluster-auto', 'cluster', is_flag=True, help='Submit jobs to cluster')
@click.option('--cluster', '--cluster-cmd', 'cluster_cmd', help='Deprecated. Use --cluster-auto instead')

# Snakemake:
@click.option('--forcerun', 'forcerun', help='Comma-separated rules that will be run even if the outputs exist. Propagated to snakemake, space-separated.')
@click.option('--unlock', is_flag=True, help='Use when you are rerunning after Ctrl+C. Propagated to snakemake.')
@click.option('--rerun-incomplete', is_flag=True, help='[Deprecated]. Propagated to snakemake. Set by default, ignored.')
@click.option('--restart-times', 'restart_times', default=2, help='Propagated to snakemake. Default is 0.')
@click.option('-n', '--dryrun', 'dryrun', is_flag=True, help='Propagated to snakemake. Prints rules and commands '
                                                             'to be run without actually executing them.')
@click.option('--report', 'report', help='Propagated to snakemake. Create an HTML report with results and statistics. '
                                         'Needs to end in ".html".')
@click.option('--dag', 'dag', is_flag=True, help='Propagated to snakemake. Print the DAG of jobs in the dot language. '
                                                 'Usage: umccrise --dag > tmp.txt; cat <cleaned-tmp.txt> | dot -Tsvg > dag.svg')
# Other:
@click.option('--s3/--no-s3'  , 'upload_s3',  default=False, help='Upload results to s3 [deprectated]')
@click.option('--igv/--no-igv', 'upload_igv', default=False, help='Generate mini-bams and upload to a s3 bucket [deprectated]')

@click.option('--docker', '--docker-wrapper-mode', 'docker_wrapper_mode', is_flag=True,
              help='Pull umccr/umccrise docker image and use it instead of the main codebase')
@click.option('--debug', 'debug', is_flag=True, help='Increases verbosity of messages')

def main(input_project, target_rule=list(), output_dir=None, sample=None, batch=None, exclude=None, input_genomes_dir=None,
         jobs=None, cluster=False, cluster_cmd=None, forcerun=None,
         unlock=False, rerun_incomplete=False, restart_times=None, dryrun=False,
         upload_s3=False, upload_igv=False, docker_wrapper_mode=False, report=None, dag=False, debug=False):
    """
Umccrise (post-process) a bcbio or Dragen project.\n
input_project: path to a bcbio run (final or "datestamp" directory) or a Dragen run\n
target_rule: optional list of rules, e.g.: pcgr coverage structural small_variants rmd igv
"""

    output_dir = output_dir or 'umccrised'
    output_dir = safe_mkdir(abspath(output_dir))
    log_dir = safe_mkdir(join(output_dir, 'log'))
    logger.init(log_fpath_=join(log_dir, 'command.txt'), save_previous=True)

    if isfile(join(output_dir, 'all.done')):
        run_simple('touch ' + join(output_dir, 'all.done'))

    conf = dict()
    docker_mounts = dict()

    #######################
    #### Setting paths ####
    #######################

    if docker_wrapper_mode:
        docker_mounts[output_dir] = '/output_dir'

    tmp_dirs = []

    if isfile(input_project):
        input_project, tmp_dir = extract_tarball_input(output_dir, input_project, 'Bcbio or Dragen project input')
        tmp_dirs.append(tmp_dir)

    conf['input_project'] = verify_dir(input_project, is_critical=True)
    if docker_wrapper_mode:
        conf['input_project'] = docker_mounts[input_project] = '/bcbio_project'

    if input_genomes_dir:
        if isfile(input_genomes_dir):
            input_genomes_dir, tmp_dir = extract_tarball_input(output_dir, input_genomes_dir, 'Genomes directory')
            tmp_dirs.append(tmp_dir)

    # check hpc_utils can find the genomes dir, and error out if not
    hpc.set_genomes_dir(input_genomes_dir)

    conf['genomes_dir'] = verify_dir(hpc.genomes_dir, is_critical=True)
    if docker_wrapper_mode:
        conf['genomes_dir'] = docker_mounts[hpc.genomes_dir] = '/genomes'
    logger.info(f'Using genomes directory: {hpc.genomes_dir}')

    #####################################
    #### Setting non-path parameters ####
    #####################################

    if sample or batch:
        conf['sample'] = sample or batch
    if exclude:
        conf['exclude'] = exclude
    target_rule = list(target_rule)
    if 'pcgr_download' in target_rule:
        conf['pcgr_download'] = 'yes'

    conf['upload_igv'] = 'yes' if upload_igv is True else 'no'

    conf['total_cores'] = jobs

    if unlock: conf['unlock'] = 'yes'

    if debug: conf['debug'] = 'yes'

    #########################
    #### Setting cluster ####
    #########################

    cluster_param = ''
    cluster_log_dir = ''
    if (cluster or cluster_cmd) and not docker_wrapper_mode:
        if cluster_cmd:
            cluster_param = f' --cluster "{cluster_cmd}"'
        else:
            cluster_log_dir = safe_mkdir(join(log_dir, 'cluster'))
            cluster_param = snakemake_utils.make_cluster_cmdl(cluster_log_dir, 'umccrise')

    ###############################
    #### Building command line ####
    ###############################

    cmd = ''
    if docker_wrapper_mode:
        cpus_avail = int(subprocess.check_output('docker system info | grep CPUs', shell=True).decode().split(': ')[1])
        if jobs > cpus_avail:
            click.echo(click.style(
                f'Warning: the number of jobs requested {jobs} is higher than the number of available CPUs '
                f'for the docker machine {cpus_avail}. Downgrading requested jobs to {cpus_avail}.', fg='red'))
            jobs = cpus_avail

        docker_tag = 'umccr/umccrise'
        # if pcgr_data:
        #     docker_tag = 'umccr/umccrise_with_pcgr'

        cmd = (
            f'docker run -t ' +
            f'--cpus {jobs} ' +
            ''.join(f'-v={k}:{v} ' for k, v in docker_mounts.items()) +
            f'{docker_tag} '
        )

    snakefile = join(package_path(), 'Snakefile') if not docker_wrapper_mode else '/umccrise/umccrise/Snakefile'
    cmd += (
        f'snakemake '
        f'{" ".join(target_rule)} '
        f'--snakefile {snakefile} '
        f'--printshellcmds '
        f'{"--dryrun " if dryrun else ""}'
        f'{"--dag " if dag else ""}'
        f'{f"--report {report} " if report else ""}'
        f'--directory {output_dir if not docker_wrapper_mode else "/output_dir"} '
        f'-j {jobs} '
        f'--rerun-incomplete '
        f'--restart-times {restart_times} '
        f'{cluster_param} '
        f'--config {" ".join(k + "=" + str(v) for k, v in conf.items())} '
    )

    #################
    #### Running ####
    #################

    if unlock:
        print('* Unlocking previous run... *')
        run_simple(cmd + ' --unlock')
        print('* Now rerunning *')

    try:
        run_simple(cmd)
    except subprocess.CalledProcessError:
        logger.error('--------')
        logger.error(f'Error running Umccrise: snakemake returned a non-zero status. Working directory: {output_dir}')
        if cluster_log_dir:
            run_simple(f'chmod -R a+r {cluster_log_dir}', silent=True)
            logger.error(f'Review cluster job logs in {cluster_log_dir}')
        for tmp_dir in tmp_dirs: tmp_dir.cleanup()
        sys.exit(1)
    except KeyboardInterrupt:
        logger.error('--------')
        logger.error(f'Interrupted Umccrise. Fixing logs permissions. Working directory: {output_dir}')
        if cluster_log_dir:
            run_simple(f'chmod -R a+r {cluster_log_dir}', silent=True)
            logger.error(f'Review cluster job logs in {cluster_log_dir}')
        for tmp_dir in tmp_dirs: tmp_dir.cleanup()
        sys.exit(1)
    else:
        logger.info('--------')
        if cluster_log_dir:
            run_simple(f'chmod -R a+r {cluster_log_dir}', silent=True)
        logger.info(f'Finished. Output directory: {output_dir}')
        for tmp_dir in tmp_dirs: tmp_dir.cleanup()


def extract_tarball_input(output_dir, path, description):
    if not path.endswith('.tar.gz'):
        critical(f'{description} must be either a directory, or a .tar.gz file: {path}')
    input_dir = safe_mkdir(join(output_dir, 'input'))
    tmp_dir = tempfile.TemporaryDirectory(prefix=input_dir)
    run_simple(f'tar -xzf {path} --directory {tmp_dir.name}')
    input_project = join(tmp_dir.name, os.listdir(tmp_dir.name)[0])
    assert isdir(input_project), input_project + " " + str(os.listdir(tmp_dir.name))
    return input_project, tmp_dir


if __name__ == '__main__':
    main()
